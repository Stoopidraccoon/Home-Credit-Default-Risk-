{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12913448,"sourceType":"datasetVersion","datasetId":8170949}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Dataset Introduction\n\nWe are using the **Home Credit Default Risk dataset** (`application_train.csv`) from the Home Credit Group challenge.  \nThis dataset contains information about loan applicants and whether they defaulted on their loan.\n\n### Dataset Overview\n- **Rows (records):** ~307,511  \n- **Columns (features):** 122+  \n- **Target Variable:** `TARGET`\n  - `0` → Loan repaid (no default)  \n  - `1` → Loan not repaid (default)  \n\n### Key Feature Groups\n- **Demographics** – gender, age, family status, education.  \n- **Financial Information** – income, employment type, credit amount.  \n- **Social & Housing** – housing type, region, family members.  \n- **Credit Behavior** – previous loan applications, payment history.  \n\n### Data Challenges\n- **Imbalanced Target** – only ~8% defaults.  \n- **Missing Values** – several categorical and numerical columns contain missing entries.  \n- **High Dimensionality** – dataset has many categorical variables that need special handling.  \n\nThis makes the dataset an **excellent case study for credit risk modeling and cost-based optimization.**\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-08-30T14:36:03.249135Z","iopub.execute_input":"2025-08-30T14:36:03.249497Z","iopub.status.idle":"2025-08-30T14:36:03.623811Z","shell.execute_reply.started":"2025-08-30T14:36:03.249435Z","shell.execute_reply":"2025-08-30T14:36:03.622938Z"}}},{"cell_type":"code","source":"# Import Libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (\n    roc_auc_score, accuracy_score, confusion_matrix, classification_report,\n    roc_curve, precision_recall_curve\n)\nfrom catboost import CatBoostClassifier, Pool\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T15:44:41.540081Z","iopub.execute_input":"2025-08-30T15:44:41.540427Z","iopub.status.idle":"2025-08-30T15:44:48.142653Z","shell.execute_reply.started":"2025-08-30T15:44:41.540401Z","shell.execute_reply":"2025-08-30T15:44:48.140840Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Load dataset\ntrain = pd.read_csv(\"/kaggle/input/home-credit-default-risk-dataset/application_train.csv\")\nprint(\"Train shape:\", train.shape)\nprint(\"Columns:\", train.columns[:15], \"...\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T15:44:51.653560Z","iopub.execute_input":"2025-08-30T15:44:51.653923Z","iopub.status.idle":"2025-08-30T15:44:59.475097Z","shell.execute_reply.started":"2025-08-30T15:44:51.653891Z","shell.execute_reply":"2025-08-30T15:44:59.473876Z"}},"outputs":[{"name":"stdout","text":"Train shape: (307511, 122)\nColumns: Index(['SK_ID_CURR', 'TARGET', 'NAME_CONTRACT_TYPE', 'CODE_GENDER',\n       'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL',\n       'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_TYPE_SUITE',\n       'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS'],\n      dtype='object') ...\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Features & Target\nTARGET = \"TARGET\"\ny = train[TARGET]\nX = train.drop(columns=[TARGET, \"SK_ID_CURR\"])  # drop ID + target","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T15:45:31.965128Z","iopub.execute_input":"2025-08-30T15:45:31.965415Z","iopub.status.idle":"2025-08-30T15:45:32.133167Z","shell.execute_reply.started":"2025-08-30T15:45:31.965393Z","shell.execute_reply":"2025-08-30T15:45:32.131952Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Handle missing values\n# Numeric → median fill\nnum_cols = X.select_dtypes(include=[np.number]).columns\nX[num_cols] = X[num_cols].fillna(X[num_cols].median())\n\n# Categorical → \"MISSING\" fill\ncat_cols = X.select_dtypes(include=[\"object\"]).columns\nX[cat_cols] = X[cat_cols].fillna(\"MISSING\")\n\n# Convert categoricals to category dtype\nfor c in cat_cols:\n    X[c] = X[c].astype(\"category\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T15:45:38.924423Z","iopub.execute_input":"2025-08-30T15:45:38.925328Z","iopub.status.idle":"2025-08-30T15:45:41.889182Z","shell.execute_reply.started":"2025-08-30T15:45:38.925170Z","shell.execute_reply":"2025-08-30T15:45:41.888336Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Train/Test Split \nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\nprint(\"Train size:\", X_train.shape, \"Validation size:\", X_val.shape)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-30T15:44:05.216Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Logistic Regression \nnumeric_features = X_train.select_dtypes(include=[np.number]).columns\nscaler = StandardScaler()\nX_train_num = scaler.fit_transform(X_train[numeric_features])\nX_val_num = scaler.transform(X_val[numeric_features])\n\nlr = LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=42)\nlr.fit(X_train_num, y_train)\nprobs_lr = lr.predict_proba(X_val_num)[:, 1]\npreds_lr = (probs_lr >= 0.5).astype(int)\n\nprint(\"\\n--- Logistic Regression ---\")\nprint(\"AUC:\", roc_auc_score(y_val, probs_lr))\nprint(\"Accuracy:\", accuracy_score(y_val, preds_lr))\nprint(\"Classification Report:\",classification_report(y_val, preds_lr))\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-30T15:44:05.216Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CatBoost \ncat_features_idx = [X.columns.get_loc(c) for c in cat_cols]\n\ntrain_pool = Pool(X_train, y_train, cat_features=cat_features_idx)\nval_pool = Pool(X_val, y_val, cat_features=cat_features_idx)\n\ncat_model = CatBoostClassifier(\n    iterations=1000,\n    learning_rate=0.05,\n    depth=6,\n    eval_metric=\"AUC\",\n    random_seed=42,\n    early_stopping_rounds=50,\n    verbose=200\n)\n\ncat_model.fit(train_pool, eval_set=val_pool)\nprobs_cb = cat_model.predict_proba(X_val)[:, 1]\npreds_cb = (probs_cb >= 0.5).astype(int)\n\nprint(\"\\n--- CatBoost ---\")\nprint(\"AUC:\", roc_auc_score(y_val, probs_cb))\nprint(\"Accuracy:\", accuracy_score(y_val, preds_cb))\nprint(classification_report(y_val, preds_cb))\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-30T15:44:05.216Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===== Utility: Cost-based threshold optimization =====\nfrom sklearn.metrics import confusion_matrix\n\ndef find_best_threshold(y_true, probs, cost_fp=100, cost_fn=10, step=0.01):\n    best_cost = np.inf\n    best_t = 0.5\n    thresholds = np.arange(0, 1, step)\n    for t in thresholds:\n        preds = (probs >= t).astype(int)\n        tn, fp, fn, tp = confusion_matrix(y_true, preds).ravel()\n        cost = fp*cost_fp + fn*cost_fn\n        if cost < best_cost:\n            best_cost = cost\n            best_t = t\n    return best_t, best_cost","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-30T15:44:05.216Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\n# Convert categorical features to \"category\" type explicitly\nfor col in cat_cols:\n    X_train[col] = X_train[col].astype(\"category\")\n    X_val[col] = X_val[col].astype(\"category\")\n\n# ===== Step 6b: XGBoost =====\nxgb = XGBClassifier(\n    n_estimators=500,\n    learning_rate=0.05,\n    max_depth=6,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    scale_pos_weight=(y_train.value_counts()[0] / y_train.value_counts()[1]),  # balance classes\n    eval_metric=\"auc\",\n    random_state=42,\n    enable_categorical=True,   \n    tree_method=\"hist\"        \n)\n\nxgb.fit(\n    X_train, y_train,\n    eval_set=[(X_val, y_val)],\n    verbose=100,\n    early_stopping_rounds=50\n)\n\nprobs_xgb = xgb.predict_proba(X_val)[:, 1]\npreds_xgb = (probs_xgb >= 0.5).astype(int)\n\nprint(\"\\n--- XGBoost ---\")\nprint(\"AUC:\", roc_auc_score(y_val, probs_xgb))\nprint(\"Accuracy:\", accuracy_score(y_val, preds_xgb))\nprint(classification_report(y_val, preds_xgb))\n\nbest_t, best_cost = find_best_threshold(y_val, probs_xgb, cost_fp=100, cost_fn=10)\nprint(f\"\\n[XGBoost] Best threshold: {best_t:.2f}, Business cost: {best_cost:.2f}\")\n\nbest_preds_xgb = (probs_xgb >= best_t).astype(int)\nprint(\"Accuracy at best threshold:\", accuracy_score(y_val, best_preds_xgb))\nprint(confusion_matrix(y_val, best_preds_xgb))\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-30T15:44:05.216Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cost-based threshold optimization \ndef find_best_threshold(y_true, probs, cost_fp=100, cost_fn=10, step=0.01):\n    best_cost = np.inf\n    best_t = 0.5\n    thresholds = np.arange(0, 1, step)\n    for t in thresholds:\n        preds = (probs >= t).astype(int)\n        tn, fp, fn, tp = confusion_matrix(y_true, preds).ravel()\n        cost = fp*cost_fp + fn*cost_fn\n        if cost < best_cost:\n            best_cost = cost\n            best_t = t\n    return best_t, best_cost\n\nbest_t, best_cost = find_best_threshold(y_val, probs_cb)\nprint(f\"\\nBest threshold: {best_t:.2f}, Business cost: {best_cost:.2f}\")\n\nbest_preds_cb = (probs_cb >= best_t).astype(int)\nprint(\"Accuracy at best threshold:\", accuracy_score(y_val, best_preds_cb))\nprint(confusion_matrix(y_val, best_preds_cb))","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-30T15:44:05.216Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Feature importance (CatBoost)\nfi = pd.DataFrame({\n    \"feature\": X.columns,\n    \"importance\": cat_model.get_feature_importance()\n}).sort_values(by=\"importance\", ascending=False).head(20)\n\nplt.figure(figsize=(8,6))\nsns.barplot(x=\"importance\", y=\"feature\", data=fi)\nplt.title(\"Top 20 CatBoost Features\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-30T15:44:05.216Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Feature Importance(Logistic Regression )\nfi_lr = pd.DataFrame({\n    \"feature\": numeric_features,\n    \"importance\": np.abs(lr.coef_[0])  # absolute value of coefficients\n}).sort_values(by=\"importance\", ascending=False).head(20)\n\nplt.figure(figsize=(8,6))\nsns.barplot(x=\"importance\", y=\"feature\", data=fi_lr)\nplt.title(\"Top 20 Logistic Regression Features\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-30T15:44:05.216Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Feature Importance(XGBoost)\nxgb_importance = xgb.feature_importances_\n\nfi_xgb = pd.DataFrame({\n    \"feature\": X.columns,\n    \"importance\": xgb_importance\n}).sort_values(by=\"importance\", ascending=False).head(20)\n\nplt.figure(figsize=(8,6))\nsns.barplot(x=\"importance\", y=\"feature\", data=fi_xgb)\nplt.title(\"Top 20 XGBoost Features\")\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-30T15:44:05.216Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ROC Curves (Logistic, XGBoost, CatBoost)\nfpr_lr, tpr_lr, _ = roc_curve(y_val, probs_lr)\nfpr_xgb, tpr_xgb, _ = roc_curve(y_val, probs_xgb)\nfpr_cb, tpr_cb, _ = roc_curve(y_val, probs_cb)\n\nplt.figure(figsize=(7,6))\nplt.plot(fpr_lr, tpr_lr, label=f\"Logistic AUC={roc_auc_score(y_val, probs_lr):.3f}\")\nplt.plot(fpr_xgb, tpr_xgb, label=f\"XGBoost AUC={roc_auc_score(y_val, probs_xgb):.3f}\")\nplt.plot(fpr_cb, tpr_cb, label=f\"CatBoost AUC={roc_auc_score(y_val, probs_cb):.3f}\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curves\")\nplt.legend()\nplt.show()\n\n# --- Precision-Recall Curves ---\nprec_lr, rec_lr, _ = precision_recall_curve(y_val, probs_lr)\nprec_xgb, rec_xgb, _ = precision_recall_curve(y_val, probs_xgb)\nprec_cb, rec_cb, _ = precision_recall_curve(y_val, probs_cb)\n\nplt.figure(figsize=(7,6))\nplt.plot(rec_lr, prec_lr, label=\"Logistic PR\")\nplt.plot(rec_xgb, prec_xgb, label=\"XGBoost PR\")\nplt.plot(rec_cb, prec_cb, label=\"CatBoost PR\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Precision-Recall Curves\")\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-30T15:44:05.216Z"}},"outputs":[],"execution_count":null}]}